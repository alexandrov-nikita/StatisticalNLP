{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from pymystem3 import Mystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stops = set(stopwords.words('russian'))\n",
    "slang_and_others = [u'я', u'а', u'да', u'но', u'тебе', u'мне', u'ты', u'и', u'у', u'на', u'ща', u'ага',\n",
    "                    u'так', u'там', u'какие', u'который', u'какая', u'туда', u'давай', u'короче', u'кажется', u'вообще',\n",
    "                    u'ну', u'не', u'чет', u'неа', u'свои', u'наше', u'хотя', u'такое', u'например', u'кароч', u'как-то',\n",
    "                    u'нам', u'хм', u'всем', u'нет', u'да', u'оно', u'своем', u'про', u'вы', u'м', u'тд',\n",
    "                    u'вся', u'кто-то', u'что-то', u'вам', u'это', u'эта', u'эти', u'этот', u'прям', u'либо', u'как', u'мы',\n",
    "                    u'просто', u'блин', u'очень', u'самые', u'твоем', u'ваша', u'кстати', u'вроде', u'типа', u'пока', u'ок',\n",
    "                   u'ох', u'ах', u'чо', u'шо', u'че', u'аж', u'а', u'б', u'в', u'г', u'д', \n",
    "                   u'е', u'ж', u'з', u'и', u'й', u'к', u'л', u'м', u'н', u'о', u'п', u'р', \n",
    "                   u'с', u'т', u'у', u'ф', u'х', u'ц', u'ч', u'ш', u'щ', u'э', u'ю', u'я']\n",
    "\n",
    "for word in slang_and_others:\n",
    "    russian_stops.add(word)\n",
    "    \n",
    "tokenizer = RegexpTokenizer('[а-я]+')\n",
    "\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, tokenizer=tokenizer):\n",
    "    # lower case and remove leading/trailing spaces\n",
    "    text = text.lower().strip().replace(u'ё', u'е')\n",
    "\n",
    "    # tokenize the text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    clean_text = ' '.join(tokens)\n",
    "    \n",
    "    # apply stemmer to each token\n",
    "    tokens = (''.join(m.lemmatize(clean_text)[:-1])).split(' ')\n",
    "    \n",
    "    tokens = [word for word in tokens if word not in russian_stops]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import hashlib\n",
    "\n",
    "sentence_hash = set()\n",
    "\n",
    "csvFile = open('../tweets/ru/all_normalized.csv', 'a')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "counter = 0\n",
    "\n",
    "with open('../tweets/ru/all.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        preprocessed = preprocess(row[1])\n",
    "        k = hashlib.md5(''.join(preprocessed).encode('utf-8')).hexdigest()\n",
    "        if k not in sentence_hash:\n",
    "            sentence_hash.add(k)\n",
    "            csvWriter.writerow([str(counter)] + preprocessed)\n",
    "            counter += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
