{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import os\n",
    "import collections\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenizer = RegexpTokenizer('\\w+')\n",
    "    \n",
    "    # lower case and remove leading/trailing spaces\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    for token in text.split():\n",
    "        # skip links, user handles and stopwords\n",
    "        if token.startswith('https://') \\\n",
    "        or token.startswith('@') \\\n",
    "        or token in stopwords.words('english'):\n",
    "            continue\n",
    "            \n",
    "        tokens.append(token)\n",
    "    \n",
    "    # tokenize the text\n",
    "    tokens = tokenizer.tokenize(' '.join(tokens))\n",
    "\n",
    "    # lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    path = '../tweets/en/all.csv'\n",
    "    \n",
    "    tweets = []\n",
    "\n",
    "    with open(path, 'r', newline='\\r\\n') as f:\n",
    "        for i, line in enumerate(f.readlines()):\n",
    "            n, tweet = line.split(',', maxsplit=1)\n",
    "            tokens = preprocess(tweet)\n",
    "\n",
    "            tweets.append(tokens)\n",
    "            \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/en/'\n",
    "model_name_template = 'model-sg={}-size={}-window={}-mincount={}-downsampling=no-{}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [0, 1] # CBOW or skip-gram\n",
    "\n",
    "# embedding output dimension\n",
    "sizes = [50, 100, 200]\n",
    "\n",
    "# it is mentioned on slides that for CBOW window is usually 5 and\n",
    "# for skip-gram 10 so let's try some values around those numbers\n",
    "#\n",
    "# access using windows[sg]\n",
    "windows = [[2, 5, 8], [5, 10, 15]]\n",
    "\n",
    "min_counts = [5, 50, 100]\n",
    "\n",
    "\n",
    "params = {\n",
    "    'architectures' : architectures,\n",
    "    'sizes' : sizes,\n",
    "    'windows' : windows,\n",
    "    'min_counts' : min_counts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(params, n=1, force_train=False):\n",
    "\n",
    "    # boolean indicating whether to train or load from file\n",
    "    # NOTE: this is a poor check\n",
    "    train = not os.listdir(model_path) or force_train\n",
    "    \n",
    "    # list of tuples [(params, model), ...]\n",
    "    models = []\n",
    "    \n",
    "    for sg in params['architectures']:\n",
    "        for size in params['sizes']:\n",
    "            for window in params['windows'][sg]:\n",
    "                for min_count in params['min_counts']:\n",
    "                        \n",
    "                    param_tuple = (sg, size, window, min_count)\n",
    "\n",
    "                    if train:\n",
    "                        model = Word2Vec(sentences=tweets, size=size, window=window, \n",
    "                                         min_count=min_count, sg=sg)\n",
    "                        model.save(model_path + \\\n",
    "                                   model_name_template.format(sg, size, window, min_count, n))\n",
    "                    else:\n",
    "                        model = Word2Vec.load(model_path + \\\n",
    "                                              model_name_template.format(sg, size, window, min_count, n))\n",
    "\n",
    "                    models.append((param_tuple, model))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_country = [\n",
    "    ('russia', 'putin'),\n",
    "    ('america', 'trump'),\n",
    "    ('britain', 'may'),\n",
    "    ('syria', 'assad'),\n",
    "    ('germany', 'merkel'),\n",
    "    ('france', 'macron'),\n",
    "    ('japan', 'abe'),\n",
    "    ('turkey', 'erdogan')\n",
    "]\n",
    "\n",
    "combinations_pres_country = [pair for pair in itertools.combinations(president_country, r=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(m, debug=0):\n",
    "    score = 0\n",
    "    count = 0\n",
    "    for equation in combinations_pres_country:\n",
    "        \n",
    "        a = equation[0][0]\n",
    "        b = equation[1][1]\n",
    "        c = equation[0][1]\n",
    "        d = equation[1][0]\n",
    "        \n",
    "        if a in m.wv.vocab and b in m.wv.vocab and c in m.wv.vocab:\n",
    "            for i, x in enumerate(m.wv.most_similar(positive=[a, b], negative=[c])):\n",
    "                if d == x[0]:\n",
    "                    score += 1.0/(i + 1)\n",
    "                    count += 1\n",
    "                    if debug == 1:\n",
    "                        print(\"Found %s for relation %s -> %s and %s -> ? in position %d\"%(d, c, a, b, i + 1))\n",
    "        \n",
    "        if c in m.wv.vocab and d in m.wv.vocab and b in m.wv.vocab:\n",
    "            for i, x in enumerate(m.wv.most_similar(positive=[c, d], negative=[b])):\n",
    "                if a == x[0]:\n",
    "                    score += 1.0/(i + 1)\n",
    "                    count += 1\n",
    "                    if debug == 1:\n",
    "                        print(\"Found %s for relation %s -> %s and %s -> ? in position %d\"%(a, b, d, c, i + 1))\n",
    "\n",
    "        if a in m.wv.vocab and c in m.wv.vocab and d in m.wv.vocab:\n",
    "            for i, x in enumerate(m.wv.most_similar(positive=[c, d], negative=[a])):\n",
    "                if b == x[0]:\n",
    "                    score += 1.0/(i + 1)\n",
    "                    count += 1\n",
    "                    if debug == 1:\n",
    "                        print(\"Found %s for relation %s -> %s and %s -> ? in position %d\"%(b, a, c, d, i + 1))\n",
    "        \n",
    "        if a in m.wv.vocab and b in m.wv.vocab and d in m.wv.vocab:\n",
    "            for i, x in enumerate(m.wv.most_similar(positive=[a, b], negative=[d])):\n",
    "                if c == x[0]:\n",
    "                    score += 1.0/(i + 1)\n",
    "                    count += 1\n",
    "                    if debug == 1:\n",
    "                        print(\"Found %s for relation %s -> %s and %s -> ? in position %d\"%(c, d, b, a, i + 1))\n",
    "                    \n",
    "    return score, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=0... ...done!\n",
      "n=1... ...done!\n",
      "n=2... ...done!\n",
      "n=3... ...done!\n"
     ]
    }
   ],
   "source": [
    "n_train = 4\n",
    "\n",
    "modelss = []\n",
    "\n",
    "for n in range(n_train):\n",
    "    print('n={}...'.format(n), end=' ')\n",
    "    models = get_models(params, n, force_train=False)\n",
    "    modelss.append(models)\n",
    "    print('...done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "print(len(modelss[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "# get mean score of n_train models\n",
    "for model_list in modelss:\n",
    "    for param_tuple, model in model_list:\n",
    "        score, count = evaluateModel(model)\n",
    "        \n",
    "        score_ = (1 / n_train) * score\n",
    "        count_ = (1 / n_train) * count\n",
    "        \n",
    "        \n",
    "        if param_tuple in scores.keys():\n",
    "            old_score, old_count = scores[param_tuple]\n",
    "            scores[param_tuple] = (old_score + score_, old_count + count_)\n",
    "        else:\n",
    "            scores[param_tuple] = (score_, count_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best embeddings:\n",
      "(1, 50, 15, 50) (40.30357142857143, 63.25)\n",
      "(1, 50, 10, 50) (35.026984126984125, 62.75)\n",
      "(1, 50, 15, 5) (28.337599206349207, 45.0)\n",
      "(1, 100, 15, 50) (26.975297619047616, 49.75)\n",
      "(1, 50, 10, 5) (26.80297619047619, 38.75)\n",
      "\n",
      "worst embeddings:\n",
      "(0, 50, 2, 5) (1.9229166666666666, 7.5)\n",
      "(0, 200, 5, 100) (1.888690476190476, 6.75)\n",
      "(0, 200, 2, 100) (1.8464285714285715, 6.5)\n",
      "(0, 100, 2, 100) (1.6033730158730157, 6.25)\n",
      "(0, 50, 2, 100) (0.6464285714285714, 3.75)\n"
     ]
    }
   ],
   "source": [
    "scores_sorted = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print('best embeddings:')\n",
    "for a, b in scores_sorted[:5]:\n",
    "    print(a, b)\n",
    "    \n",
    "print()\n",
    "\n",
    "print('worst embeddings:')\n",
    "for a, b in scores_sorted[-5:]:\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramstuple2model(params):\n",
    "    sg, size, window, min_count = params\n",
    "    \n",
    "    if sg == 0:\n",
    "        windows = [[window],[]]\n",
    "    else:\n",
    "        windows = [[], [window]]\n",
    "\n",
    "    params_dict = dict(architectures=[sg], sizes=[size], windows=windows, min_counts=[min_count])\n",
    "    \n",
    "    return get_models(params_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found russia for relation trump -> america and putin -> ? in position 9\n",
      "Found russia for relation may -> britain and putin -> ? in position 4\n",
      "Found putin for relation britain -> may and russia -> ? in position 7\n",
      "Found russia for relation assad -> syria and putin -> ? in position 1\n",
      "Found assad for relation russia -> putin and syria -> ? in position 10\n",
      "Found germany for relation putin -> russia and merkel -> ? in position 4\n",
      "Found russia for relation merkel -> germany and putin -> ? in position 1\n",
      "Found putin for relation germany -> merkel and russia -> ? in position 3\n",
      "Found france for relation putin -> russia and macron -> ? in position 1\n",
      "Found russia for relation macron -> france and putin -> ? in position 1\n",
      "Found macron for relation russia -> putin and france -> ? in position 1\n",
      "Found putin for relation france -> macron and russia -> ? in position 1\n",
      "Found japan for relation putin -> russia and abe -> ? in position 1\n",
      "Found russia for relation abe -> japan and putin -> ? in position 1\n",
      "Found abe for relation russia -> putin and japan -> ? in position 1\n",
      "Found putin for relation japan -> abe and russia -> ? in position 2\n",
      "Found turkey for relation putin -> russia and erdogan -> ? in position 1\n",
      "Found russia for relation erdogan -> turkey and putin -> ? in position 1\n",
      "Found erdogan for relation russia -> putin and turkey -> ? in position 1\n",
      "Found putin for relation turkey -> erdogan and russia -> ? in position 1\n",
      "Found britain for relation trump -> america and may -> ? in position 7\n",
      "Found america for relation may -> britain and trump -> ? in position 8\n",
      "Found assad for relation america -> trump and syria -> ? in position 1\n",
      "Found france for relation trump -> america and macron -> ? in position 1\n",
      "Found japan for relation trump -> america and abe -> ? in position 1\n",
      "Found abe for relation america -> trump and japan -> ? in position 1\n",
      "Found germany for relation may -> britain and merkel -> ? in position 8\n",
      "Found merkel for relation britain -> may and germany -> ? in position 5\n",
      "Found france for relation may -> britain and macron -> ? in position 1\n",
      "Found britain for relation macron -> france and may -> ? in position 6\n",
      "Found macron for relation britain -> may and france -> ? in position 5\n",
      "Found japan for relation may -> britain and abe -> ? in position 1\n",
      "Found abe for relation britain -> may and japan -> ? in position 1\n",
      "Found turkey for relation may -> britain and erdogan -> ? in position 6\n",
      "Found erdogan for relation britain -> may and turkey -> ? in position 7\n",
      "Found germany for relation assad -> syria and merkel -> ? in position 9\n",
      "Found france for relation assad -> syria and macron -> ? in position 5\n",
      "Found syria for relation macron -> france and assad -> ? in position 5\n",
      "Found japan for relation assad -> syria and abe -> ? in position 1\n",
      "Found turkey for relation assad -> syria and erdogan -> ? in position 1\n",
      "Found syria for relation erdogan -> turkey and assad -> ? in position 1\n",
      "Found erdogan for relation syria -> assad and turkey -> ? in position 7\n",
      "Found assad for relation turkey -> erdogan and syria -> ? in position 3\n",
      "Found france for relation merkel -> germany and macron -> ? in position 1\n",
      "Found macron for relation germany -> merkel and france -> ? in position 1\n",
      "Found merkel for relation france -> macron and germany -> ? in position 5\n",
      "Found japan for relation merkel -> germany and abe -> ? in position 1\n",
      "Found abe for relation germany -> merkel and japan -> ? in position 2\n",
      "Found turkey for relation merkel -> germany and erdogan -> ? in position 10\n",
      "Found germany for relation erdogan -> turkey and merkel -> ? in position 7\n",
      "Found erdogan for relation germany -> merkel and turkey -> ? in position 7\n",
      "Found japan for relation macron -> france and abe -> ? in position 1\n",
      "Found france for relation abe -> japan and macron -> ? in position 1\n",
      "Found abe for relation france -> macron and japan -> ? in position 1\n",
      "Found macron for relation japan -> abe and france -> ? in position 3\n",
      "Found turkey for relation macron -> france and erdogan -> ? in position 3\n",
      "Found france for relation erdogan -> turkey and macron -> ? in position 2\n",
      "Found erdogan for relation france -> macron and turkey -> ? in position 1\n",
      "Found macron for relation turkey -> erdogan and france -> ? in position 1\n",
      "Found turkey for relation abe -> japan and erdogan -> ? in position 1\n",
      "Found japan for relation erdogan -> turkey and abe -> ? in position 1\n",
      "Found erdogan for relation japan -> abe and turkey -> ? in position 9\n",
      "Found abe for relation turkey -> erdogan and japan -> ? in position 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39.80714285714285"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = paramstuple2model(scores_sorted[0][0])[0][1]\n",
    "s1, s2 = evaluateModel(best_model, 1)\n",
    "\n",
    "s1 + s2 # total score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['syria', 'damascus', 'assad', 'politics', 'putin', 'trump', 'russia', 'usa', 'skripal', 'uk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('west', 'capital', 'syrian', 'religion', 'russia', 'republican', 'russian', '99', 'bz', 'france')\n",
      "('syriaairstrikes', 'rubble', 'punish', 'political', 'buddy', 'one', 'putin', 'mexico', 'swiss', 'britain')\n",
      "('syriastrike', 'raw', 'syria', 'age', 'again', 'impeachment', 'kremlin', '8', 'salisbury', 'theresamay')\n",
      "('punish', 'square', 'civilian', 'relevant', 'russian', 'potus', 'u', 'com', 'poisoning', 'accuses')\n",
      "('assad', 'yesterday', 'weapon', 'idea', 'vlad', 'president', 'coming', 'free', 'produced', 'k')\n",
      "('u', 'night', 'chemical', 'platform', 'puppet', 'mueller', 'syria', 'hot', 'motive', 'fr')\n",
      "('syrian', '14', 'basically', 'character', 'vladimir', 'democrat', 'diplomat', 'spain', 'poisoned', 'skripal')\n",
      "('chemicalweapons', 'precise', 'attack', 'mix', 'kremlin', 'even', 'prepared', 'worldwide', 'uk', 'boris')\n",
      "('vow', 'explosion', 'regime', 'college', 'would', 'him', 'prepare', 'drama', 'evidence', 'salisbury')\n",
      "('global', 'playlist', 'butcher', 'topic', 'west', 'gop', 'ending', 'sport', 'agent', 'embassy')\n",
      "----------------------------\n",
      "('syriaairstrikes', 'missionaccomplished', 'syrian', 'relevant', 'russia', 'him', 'putin', 'free', 'bz', 'france')\n",
      "('syriastrike', 'capital', 'syria', 'religion', 'again', 'impeachment', 'russian', 'mexico', 'swiss', 'fr')\n",
      "('assad', 'syriaairstrikes', 'weapon', 'nasty', 'buddy', 'he', 'kremlin', 'spain', 'salisbury', 'britain')\n",
      "('west', 'yesterday', 'punish', 'ignorance', 'vladimir', 'crooked', 'u', 'x', 'motive', 'theresamay')\n",
      "('u', 'raw', 'nikkihaley', 'always', 'vlad', 'comey', 'syria', 'steel', 'poisoned', 'spain')\n",
      "('syriastrikes', 'rubble', 'civilian', 'character', 'russian', 'office', 'diplomat', 'italy', 'lavrov', 'skripal')\n",
      "('punish', 'syriastrike', 'regime', 'culture', 'mess', 'crook', 'attack', 'amazon', 'poisoning', 'accuses')\n",
      "('rouhani', 'night', 'basically', 'political', 'intention', 'rant', 'coming', 'drama', 'recent', 'k')\n",
      "('chemicalweapons', '14', 'absolutely', 'reading', 'puppet', 'realdonaldtrump', 'prepare', '99', 'produced', 'foiled')\n",
      "('vow', 'saa', 'genocide', 'aside', 'warn', 'even', 'possible', 'mix', 'agent', 'poisoned')\n",
      "----------------------------\n",
      "('assad', 'capital', 'syria', 'gender', 'russia', 'appointee', 'russian', 'cinema', 'skripals', 'france')\n",
      "('unitedstates', 'syriabombing', 'syrian', 'religion', 'buddy', 'impeachtrumpnow', 'putin', 'tshirt', 'novichok', 'itvnews')\n",
      "('foresees', 'reduces', 'retaliating', 'political', 'hmmmm', 'muellerinvestigation', 'diplomat', 'sofary', 'bz', 'fra')\n",
      "('basnews', 'hamza', 'regime', 'appreciate', 'dangerously', 'notmypresident', 'kremlin', 'hiphop', 'salisbury', 'fr')\n",
      "('vladimirputin', 'syriastrike', 'inhumane', 'practiced', 'again', 'loudobbs', 'rf', 'tab', 'toxin', 'pmqs')\n",
      "('syriaairstrikes', 'missionaccomplished', 'supplying', 'race', 'russian', 'muellertime', 'reutersus', 'freestyle', 'swiss', 'bbcqt')\n",
      "('basharalassad', 'decry', 'unaffected', 'prosperity', 'kremlin', 'one', 'glove', 'mvp', 'substance', 'votelabour')\n",
      "('foreignpolicy', 'rubble', 'fortunately', 'lecture', 'glove', 'sank', 'provoking', 'newyorkcity', 'yulia', 'fukus')\n",
      "('déjà', 'syriastrikes', 'chemical', 'disappointing', 'teheran', 'resister', 'promising', 'disco', 'spiez', 'marilynlavala')\n",
      "('vía', 'assadmustgo', 'insist', 'bigotry', 'poo', 'impeachtrumppence', 'vodka', 'beach', 'poisoning', 'reacts')\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# best model according to president-country metric\n",
    "best_models = [paramstuple2model(params)[0][1] for params, score in scores_sorted[:3]]\n",
    "\n",
    "for i, model in enumerate(best_models):\n",
    "    \n",
    "    xs = [[word for word, _ in model.wv.most_similar(keyword)] for keyword in keywords]\n",
    "\n",
    "    for a in (list(zip(*xs))):\n",
    "        print(a)\n",
    "        \n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('coalition', 'wall', 'ability', 'liberal', 'russian', 'realdonaldtrump', 'israel', 'home', 'produced', 'britain')\n",
      "('diplomacy', 'explosion', 'change', 'folk', 'russia', 'losing', 'russian', 'mexico', 'nerve', 'k')\n",
      "('planned', 'city', 'isi', 'respect', 'monster', 'obama', 'hezbollah', 'free', 'agent', 'england')\n",
      "('condemn', 'empty', 'iranian', 'leftist', 'relationship', 'j', 'turkey', 'australia', 'deadly', 'ally')\n",
      "('following', 'capital', 'islam', 'business', 'donald', 'elected', 'nuke', 'car', 'poisoning', 'germany')\n",
      "('tn', 'building', 'however', 'crazy', 'enemy', 'graham', 'north', 'canada', 'alleged', 'london')\n",
      "('response', 'area', 'brutal', 'game', 'ally', 'idiot', 'korea', 'service', 'suspected', 'intelligence')\n",
      "('dropping', 'yesterday', 'him', 'amazing', 'israel', 'potus', 'economic', 'africa', 'confirmed', 'push')\n",
      "('allied', 'ghouta', 'continue', 'ur', 'iran', 'him', 'phone', 'driver', 'cw', 'british')\n",
      "('empty', 'future', 'dictator', 'political', 'master', 'joe', 'saudi', 'eu', 'purpose', 'n')\n",
      "----------------------------\n",
      "('diplomacy', 'explosion', 'ability', 'liberal', 'russian', 'realdonaldtrump', 'israel', 'mexico', 'nerve', 'britain')\n",
      "('coalition', 'yesterday', 'change', 'folk', 'monster', 'losing', 'russian', 'car', 'produced', 'k')\n",
      "('ally', 'city', 'dictator', 'sad', 'behavior', 'idiot', 'hezbollah', 'australia', 'agent', 'england')\n",
      "('planned', 'capital', 'iranian', 'political', 'enemy', 'obama', 'turkey', 'free', 'deadly', 'ally')\n",
      "('condemn', 'coalition', 'anyone', 'crazy', 'everything', 'graham', 'saudi', 'africa', 'alleged', 'germany')\n",
      "('humanitarian', 'ghouta', 'hard', 'cut', 'russia', 'bos', 'directly', 'canada', 'suspected', 'british')\n",
      "('recent', 'syrianstrikes', 'brutal', 'mouth', 'consequence', 'j', 'phone', 'driver', 'sarin', 'intelligence')\n",
      "('response', 'empty', 'him', 'lmao', 'how', 'resign', 'diplomacy', 'india', 'cw', 'n')\n",
      "('basically', 'wall', 'saddam', 'amazing', 'saddam', 'vladimir', 'corbyn', 'travel', 'hedge', 'push')\n",
      "('siria', 'ruin', 'rebel', 'game', 'iran', 'joe', 'arabia', 'service', 'confirmed', 'israeli')\n",
      "----------------------------\n",
      "('coalition', 'explosion', 'ability', 'folk', 'monster', 'realdonaldtrump', 'israel', 'mexico', 'nerve', 'britain')\n",
      "('planned', 'saa', 'change', 'liberal', 'how', 'losing', 'turkey', 'service', 'agent', 'k')\n",
      "('following', 'area', 'basically', 'mouth', 'graham', 'graham', 'directly', 'car', 'deadly', 'england')\n",
      "('condemn', 'city', 'continue', 'piece', 'iran', 'potus', 'hezbollah', 'australia', 'alleged', 'british')\n",
      "('diplomacy', 'yesterday', 'rebel', 'history', 'trouble', 'bernie', 'saudi', 'canada', 'produced', 'germany')\n",
      "('saa', 'ruin', 'civilian', 'short', 'who', 'him', 'syriastrike', 'home', 'suspected', 'intelligence')\n",
      "('tn', 'capital', 'brutal', 'business', 'erdogan', 'idiot', 'arabia', 'art', 'cw', 'ally')\n",
      "('recent', 'turned', 'iranian', 'attention', 'mob', 'obama', 'russian', 'india', 'hedge', 'n')\n",
      "('syriastrike', 'coalition', 'others', 'racism', 'resign', 'bos', 'korea', 'free', 'chemicalweapons', 'london')\n",
      "('wwiii', 'syrianstrikes', 'there', 'more', 'israel', 'resign', 'germany', 'eu', 'poisoning', 'israeli')\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# worst models according to president-country metric\n",
    "worst_models = [paramstuple2model(params)[0][1] for params, score in scores_sorted[-3:]]\n",
    "\n",
    "for i, model in enumerate(worst_models):\n",
    "    \n",
    "    xs = [[word for word, _ in model.wv.most_similar(keyword)] for keyword in keywords]\n",
    "\n",
    "    for a in (list(zip(*xs))):\n",
    "        print(a)\n",
    "        \n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = '/work/courses/unix/T/ELEC/E5550/data/eval/analogical_reasoning_questions-words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19544\n"
     ]
    }
   ],
   "source": [
    "combinations = []\n",
    "\n",
    "with open(eval_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        \n",
    "        if line.startswith(':'):\n",
    "            continue\n",
    "        else:\n",
    "            a, b, c, d = line.split()\n",
    "            combinations.append(((a, b), (c, d)))\n",
    "            \n",
    "print(len(combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel2(m, combinations):\n",
    "    found = 0\n",
    "    \n",
    "    for equation in combinations:\n",
    "        \n",
    "        a = equation[0][0]\n",
    "        b = equation[1][1]\n",
    "        c = equation[0][1]\n",
    "        d = equation[1][0]\n",
    "        \n",
    "        if a in m.wv.vocab and b in m.wv.vocab and c in m.wv.vocab:\n",
    "            for i, x in enumerate(m.wv.most_similar(positive=[a, b], negative=[c])):\n",
    "                if d == x[0]:\n",
    "                    found += 1\n",
    "        \n",
    "        if c in m.wv.vocab and d in m.wv.vocab and b in m.wv.vocab:\n",
    "            for i, x in enumerate(m.wv.most_similar(positive=[c, d], negative=[b])):\n",
    "                if a == x[0]:\n",
    "                    found += 1\n",
    "\n",
    "        if a in m.wv.vocab and c in m.wv.vocab and d in m.wv.vocab:\n",
    "            for i, x in enumerate(m.wv.most_similar(positive=[c, d], negative=[a])):\n",
    "                if b == x[0]:\n",
    "                    found += 1\n",
    "                    \n",
    "        if a in m.wv.vocab and b in m.wv.vocab and d in m.wv.vocab:\n",
    "            for i, x in enumerate(m.wv.most_similar(positive=[a, b], negative=[d])):\n",
    "                if c == x[0]:\n",
    "                    found += 1\n",
    "                    \n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_eval = {}\n",
    "\n",
    "# get mean score of n_train models\n",
    "for model_list in modelss[:1]:\n",
    "    for param_tuple, model in model_list:\n",
    "        score = evaluateModel2(model, combinations)\n",
    "            \n",
    "        scores[param_tuple] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((1, 100, 5, 5), 1008), ((1, 200, 5, 5), 976), ((1, 50, 5, 5), 952), ((1, 200, 10, 50), 946), ((1, 100, 5, 50), 938), ((1, 200, 5, 50), 900), ((0, 200, 2, 5), 874), ((0, 50, 2, 5), 834), ((1, 100, 10, 50), 830), ((1, 50, 5, 50), 782), ((0, 100, 2, 5), 774), ((1, 50, 10, 5), 774), ((1, 200, 15, 50), 768), ((1, 50, 10, 50), 748), ((0, 200, 5, 5), 746), ((1, 100, 15, 50), 740), ((0, 50, 8, 5), 734), ((0, 50, 2, 50), 722), ((0, 100, 5, 5), 722), ((0, 100, 8, 5), 712), ((1, 50, 15, 50), 712), ((0, 50, 5, 5), 694), ((1, 100, 10, 5), 672), ((0, 200, 8, 5), 652), ((1, 50, 15, 5), 644), ((0, 200, 2, 50), 640), ((0, 100, 2, 50), 636), ((0, 200, 5, 50), 616), ((1, 200, 10, 5), 612), ((1, 100, 5, 100), 604), ((1, 200, 15, 5), 600), ((1, 200, 10, 100), 594), ((0, 100, 5, 50), 566), ((1, 100, 10, 100), 544), ((1, 100, 15, 5), 544), ((0, 50, 5, 50), 542), ((1, 200, 5, 100), 542), ((0, 100, 8, 50), 528), ((1, 50, 5, 100), 526), ((0, 50, 8, 50), 504), ((1, 200, 15, 100), 502), ((0, 100, 2, 100), 488), ((1, 50, 10, 100), 482), ((1, 100, 15, 100), 478), ((0, 200, 8, 50), 476), ((0, 50, 2, 100), 464), ((0, 200, 2, 100), 440), ((0, 50, 8, 100), 386), ((1, 50, 15, 100), 382), ((0, 100, 5, 100), 376), ((0, 50, 5, 100), 362), ((0, 200, 5, 100), 360), ((0, 100, 8, 100), 332), ((0, 200, 8, 100), 288)]\n"
     ]
    }
   ],
   "source": [
    "scores_eval_sorted = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "print(scores_eval_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('syriaairstrikes', 'capital', 'asad', 'religion', 'vlad', 'duh', 'kremlin', 'austria', 'novichok', 'britain')\n",
      "('provoke', 'yesterday', 'inhumane', 'gender', 'blackmail', 'drumpf', 'affect', 'bangladesh', 'skripals', 'waging')\n",
      "('039', 'city', 'killer', 'race', 'vendetta', 'bigly', 'directly', 'argentina', 'bz', 'britian')\n",
      "('punish', 'gathered', 'assertion', 'appreciate', 'buddy', 'clown', 'trigger', 'denmark', 'toxin', 'france')\n",
      "('assadmustgo', 'triple', 'assads', 'identity', 'chump', 'deflection', 'russian', 'america', 'substance', 'truthnation')\n",
      "('unitedstates', 'saa', 'punish', 'perspective', 'vladimir', 'thehill', 'reutersus', 'bride', 'salisbury', 'k')\n",
      "('reutersus', 'jolted', 'insist', 'opinion', 'puppet', 'wh', 'grows', 'brazil', 'swiss', 'stopthewar')\n",
      "('middleeast', 'decry', 'asaad', 'feeling', 'betray', 'jeff', 'careful', 'sauce', 'poisoned', 'unitedkingdom')\n",
      "('fukus', 'syrianstrike', 'further', 'culture', 'spineless', 'reviewed', 'diplomat', 'malaysia', 'irrefutable', 'fra')\n",
      "('vladimirputin', 'hamza', 'accomplice', 'sharing', 'retaliating', 'impeachment', 'miscommunication', 'mexico', 'covert', 'trick')\n"
     ]
    }
   ],
   "source": [
    "best_model = paramstuple2model(scores_eval_sorted[0][0])[0][1]\n",
    "\n",
    "xs = [[word for word, _ in best_model.wv.most_similar(keyword)] for keyword in keywords]\n",
    "\n",
    "for a in (list(zip(*xs))):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mouse', 0.8952155113220215),\n",
       " ('pursuit', 0.7874118685722351),\n",
       " ('hunted', 0.7774225473403931),\n",
       " ('navy', 0.7462985515594482),\n",
       " ('submarine', 0.7173159718513489),\n",
       " ('royal', 0.6956762075424194),\n",
       " ('hub', 0.6869996190071106),\n",
       " ('sub', 0.6750925779342651),\n",
       " ('download', 0.6705496311187744),\n",
       " ('webcam', 0.6640481948852539)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.wv.most_similar('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('syrian', 'area', 'ability', 'self', 'russian', 'realdonaldtrump', 'russian', 'africa', 'nerve', 'britain')\n",
      "('response', 'capital', 'syrian', 'crazy', 'russia', 'losing', 'israel', 'free', 'spy', 'k')\n",
      "('syriastrike', 'near', 'change', 'folk', 'option', 'bos', 'korea', 'mexico', 'agent', 'england')\n",
      "('ally', 'explosion', 'capability', 'working', 'again', 'gowdy', 'option', 'canada', 'confirmed', 'germany')\n",
      "('nato', 'casualty', 'civilian', 'piece', 'buddy', 'potus', 'north', 'australia', 'poisoning', 'british')\n",
      "('coalition', 'building', 'rebel', 'religion', 'promise', 'distract', 'threat', 'share', 'claim', 'poisoning')\n",
      "('condemn', 'hit', 'also', 'liberal', 'backing', 'congressional', 'saudi', 'product', 'alleged', 'push')\n",
      "('hezbollah', 'sent', 'response', 'mind', 'master', 'mob', 'nuke', 'sport', 'suspected', 'ally')\n",
      "('syriacrisis', 'equipment', 'iranian', 'low', 'enemy', 'democrat', 'turkey', 'london', 'independent', 'recent')\n",
      "('capability', 'empty', 'so', 'reading', 'everything', 'pardon', 'kim', 'car', 'intelligence', 'macron')\n"
     ]
    }
   ],
   "source": [
    "worst_model = paramstuple2model(scores_eval_sorted[-1][0])[0][1]\n",
    "\n",
    "xs = [[word for word, _ in worst_model.wv.most_similar(keyword)] for keyword in keywords]\n",
    "\n",
    "for a in (list(zip(*xs))):\n",
    "    print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
